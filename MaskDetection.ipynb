{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19dd4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6cdfc5",
   "metadata": {},
   "source": [
    "# Step 1: Chose a prebuilt model\n",
    "\n",
    "There are currently 3 models:\n",
    "\n",
    " + A basic nureal net\n",
    " + InceptionV3\n",
    " + MobileNetV2\n",
    " \n",
    " If you don't know which one, the fastest and best is usually MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22800db4",
   "metadata": {},
   "source": [
    "### Basic Nuralnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7801d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mask_detector_basic.model')\\\n",
    "labels_dict={0:'without_mask',1:'with_mask'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214f0a8",
   "metadata": {},
   "source": [
    "### MobileNetV2 Model (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35d5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mask_detector_mobilenet.model')\n",
    "labels_dict={1:'without_mask',0:'with_mask'}\n",
    "color_dict={1:(0,0,255),0:(0,255,0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690999a",
   "metadata": {},
   "source": [
    "### InceptionV3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274c8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"mask_detector_inceptionv3.model\")\n",
    "labels_dict={1:'without_mask',0:'with_mask'}\n",
    "color_dict={1:(0,0,255),0:(0,255,0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997be3ae",
   "metadata": {},
   "source": [
    "# Step 2: Use the model on the webcam feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5caabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "size = 4\n",
    "webcam = cv2.VideoCapture(0) #Use camera 0\n",
    "\n",
    "# We load the xml file for the face detection\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    (rval, im) = webcam.read()\n",
    "    im=cv2.flip(im,1,1) #Flip to act as a mirror\n",
    "\n",
    "    # Resize the image to speed up detection\n",
    "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
    "\n",
    "    # detect MultiScale / faces \n",
    "    faces = classifier.detectMultiScale(mini)\n",
    "\n",
    "    # Draw rectangles around each face\n",
    "    for f in faces:\n",
    "        \n",
    "        (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
    "        cv2.putText(im,str(faces), (50, 50),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    " \n",
    "        #Save just the rectangle faces in SubRecFaces\n",
    "        face_img = im[y-30:y+h+30, x-30:x+w+30]\n",
    "        resized=cv2.resize(face_img,(200,200))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,200,200,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model.predict(reshaped)\n",
    "        #print(result)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(im, labels_dict[label] + str(round(result[0][label],2)), (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "    # Show the image\n",
    "    cv2.imshow('Mask detector',  im)\n",
    "    key = cv2.waitKey(10)\n",
    "    # if Esc key is press then break out of the loop \n",
    "    if key == 27: #The Esc key\n",
    "        break\n",
    "# Stop video\n",
    "webcam.release()\n",
    "\n",
    "# Close all started windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740515a",
   "metadata": {},
   "source": [
    "## Below is how the models were built. Feel free to modify as you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1767af",
   "metadata": {},
   "source": [
    "You'll first need to clone the dataset if you want to rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b924807",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/prajnasb/observations.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08691af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1376 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Import the dataset as an ImageDataGenerator\n",
    "\n",
    "TRAINING_DIR = \"observations/experiements/data/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(200,200))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e1625",
   "metadata": {},
   "source": [
    "## + Simple NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0b831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a basic neural net with binary return values.\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a718f7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pinchas/anaconda3/envs/main/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138/138 [==============================] - 17s 114ms/step - loss: 0.8233 - acc: 0.5368\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.6904 - acc: 0.5230\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.6906 - acc: 0.5519\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.6423 - acc: 0.6632\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 15s 110ms/step - loss: 0.4971 - acc: 0.7729\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.4426 - acc: 0.81511s - loss: 0.\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.3362 - acc: 0.8664\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 15s 110ms/step - loss: 0.3563 - acc: 0.8551\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.3723 - acc: 0.8385\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.3340 - acc: 0.8740\n"
     ]
    }
   ],
   "source": [
    "#Build the model...\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=10)\n",
    "\n",
    "#and save it\n",
    "\n",
    "model.save(\"mask_detector_basic.model\", save_format=\"h5\")\n",
    "\n",
    "# then go try the camera feed like above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923542f",
   "metadata": {},
   "source": [
    "## + MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c888090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "#Import MobileNet using the imagenet weights\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "    input_shape=(200, 200,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7dac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the end layers to the model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(5, 5))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(1024, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "#Freeze the imported layers\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb27fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138/138 [==============================] - 16s 101ms/step - loss: 0.3492\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 14s 100ms/step - loss: 0.1642\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.1153\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 14s 100ms/step - loss: 0.0978\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.0832\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 15s 109ms/step - loss: 0.0770\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 14s 104ms/step - loss: 0.0849\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 14s 104ms/step - loss: 0.0806\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 14s 103ms/step - loss: 0.0675\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 14s 105ms/step - loss: 0.0788\n"
     ]
    }
   ],
   "source": [
    "#build \n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=10)\n",
    "# and save\n",
    "model.save(\"mask_detector_mobilenet.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343cf2c",
   "metadata": {},
   "source": [
    "## + InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04b88dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 10, 10, 768)\n"
     ]
    }
   ],
   "source": [
    "#Import InceptionV3 using the imagenet weights\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape=(200, 200, 3),\n",
    " include_top=False,\n",
    " weights=\"imagenet\")\n",
    "\n",
    "#lock the premade layers\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "#define the final layers\n",
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ef5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138/138 [==============================] - 16s 99ms/step - loss: 0.0901\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.2101\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.0984\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.1260\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 14s 100ms/step - loss: 0.0624\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 15s 112ms/step - loss: 0.1173\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 14s 101ms/step - loss: 0.0842\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.1040\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.0558\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 14s 99ms/step - loss: 0.0787\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16e444bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mask_detector_inceptionv3.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32783fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
